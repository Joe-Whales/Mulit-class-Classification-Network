{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5000\n",
      "Number of classes: 4\n",
      "Train set size: 96000\n",
      "Validation set size: 24000\n",
      "Test set size: 7600\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load the data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # text = re.sub(r'\\d+', '<NUM>', text)\n",
    "    # text = re.sub(r'\\$\\d+(\\.\\d{2})?', '<MONEY>', text)\n",
    "    # text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Preprocess the text data, concat Description and Title\n",
    "df_train['processed_text'] = (df_train[\"Title\"] + \" \" + df_train[\"Description\"]).apply(preprocess_text)\n",
    "df_test['processed_text'] = (df_test[\"Title\"] + \" \" + df_test[\"Description\"]).apply(preprocess_text)\n",
    "\n",
    "\n",
    "# Create CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train_full = vectorizer.fit_transform(df_train['processed_text']).toarray()\n",
    "X_test = vectorizer.transform(df_test['processed_text']).toarray()\n",
    "\n",
    "# Cap counts to 1\n",
    "X_train_full[X_train_full > 1] = 1\n",
    "X_test[X_test > 1] = 1\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = {label: i for i, label in enumerate(df_train['Class Index'].unique())}\n",
    "y_train_full = df_train['Class Index'].map(label_encoder).values\n",
    "y_test = df_test['Class Index'].map(label_encoder).values\n",
    "\n",
    "# Split train data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.LongTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TextDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vectorizer.get_feature_names_out())}\")\n",
    "print(f\"Number of classes: {len(label_encoder)}\")\n",
    "print(f\"Train set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch [1/10]\n",
      "  Train Loss: 0.5937, Train Accuracy: 0.8653\n",
      "  Val Loss: 0.3953, Val Accuracy: 0.8896\n",
      "Epoch [2/10]\n",
      "  Train Loss: 0.3375, Train Accuracy: 0.9040\n",
      "  Val Loss: 0.3349, Val Accuracy: 0.8979\n",
      "Epoch [3/10]\n",
      "  Train Loss: 0.2842, Train Accuracy: 0.9143\n",
      "  Val Loss: 0.3138, Val Accuracy: 0.9004\n",
      "Epoch [4/10]\n",
      "  Train Loss: 0.2552, Train Accuracy: 0.9206\n",
      "  Val Loss: 0.3052, Val Accuracy: 0.9007\n",
      "Epoch [5/10]\n",
      "  Train Loss: 0.2358, Train Accuracy: 0.9257\n",
      "  Val Loss: 0.3018, Val Accuracy: 0.9004\n",
      "Epoch [6/10]\n",
      "  Train Loss: 0.2217, Train Accuracy: 0.9297\n",
      "  Val Loss: 0.3018, Val Accuracy: 0.8985\n",
      "Epoch [7/10]\n",
      "  Train Loss: 0.2107, Train Accuracy: 0.9326\n",
      "  Val Loss: 0.3031, Val Accuracy: 0.8978\n",
      "Epoch [8/10]\n",
      "  Train Loss: 0.2018, Train Accuracy: 0.9353\n",
      "  Val Loss: 0.3049, Val Accuracy: 0.8965\n",
      "Epoch [9/10]\n",
      "  Train Loss: 0.1945, Train Accuracy: 0.9372\n",
      "  Val Loss: 0.3075, Val Accuracy: 0.8958\n",
      "Epoch [10/10]\n",
      "  Train Loss: 0.1881, Train Accuracy: 0.9386\n",
      "  Val Loss: 0.3107, Val Accuracy: 0.8952\n",
      "\n",
      "Fold 2\n",
      "Epoch [1/10]\n",
      "  Train Loss: 0.5937, Train Accuracy: 0.8630\n",
      "  Val Loss: 0.3960, Val Accuracy: 0.8915\n",
      "Epoch [2/10]\n",
      "  Train Loss: 0.3377, Train Accuracy: 0.9030\n",
      "  Val Loss: 0.3350, Val Accuracy: 0.8979\n",
      "Epoch [3/10]\n",
      "  Train Loss: 0.2846, Train Accuracy: 0.9144\n",
      "  Val Loss: 0.3142, Val Accuracy: 0.9005\n",
      "Epoch [4/10]\n",
      "  Train Loss: 0.2556, Train Accuracy: 0.9209\n",
      "  Val Loss: 0.3051, Val Accuracy: 0.9008\n",
      "Epoch [5/10]\n",
      "  Train Loss: 0.2362, Train Accuracy: 0.9259\n",
      "  Val Loss: 0.3019, Val Accuracy: 0.8999\n",
      "Epoch [6/10]\n",
      "  Train Loss: 0.2220, Train Accuracy: 0.9289\n",
      "  Val Loss: 0.3012, Val Accuracy: 0.8990\n",
      "Epoch [7/10]\n",
      "  Train Loss: 0.2110, Train Accuracy: 0.9321\n",
      "  Val Loss: 0.3023, Val Accuracy: 0.8984\n",
      "Epoch [8/10]\n",
      "  Train Loss: 0.2021, Train Accuracy: 0.9350\n",
      "  Val Loss: 0.3048, Val Accuracy: 0.8970\n",
      "Epoch [9/10]\n",
      "  Train Loss: 0.1945, Train Accuracy: 0.9369\n",
      "  Val Loss: 0.3075, Val Accuracy: 0.8966\n",
      "Epoch [10/10]\n",
      "  Train Loss: 0.1882, Train Accuracy: 0.9398\n",
      "  Val Loss: 0.3110, Val Accuracy: 0.8955\n",
      "\n",
      "K-fold Cross-validation Results:\n",
      "Mean Accuracy: 0.8953\n",
      "Standard Deviation: 0.0001\n",
      "\n",
      "Training on full training set:\n",
      "Epoch [1/10]\n",
      "  Train Loss: 0.4752, Train Accuracy: 0.8807\n",
      "  Val Loss: 0.3329, Val Accuracy: 0.9005\n",
      "Epoch [2/10]\n",
      "  Train Loss: 0.2929, Train Accuracy: 0.9087\n",
      "  Val Loss: 0.2984, Val Accuracy: 0.9052\n",
      "Epoch [3/10]\n",
      "  Train Loss: 0.2602, Train Accuracy: 0.9162\n",
      "  Val Loss: 0.2884, Val Accuracy: 0.9054\n",
      "Epoch [4/10]\n",
      "  Train Loss: 0.2433, Train Accuracy: 0.9199\n",
      "  Val Loss: 0.2870, Val Accuracy: 0.9043\n",
      "Epoch [5/10]\n",
      "  Train Loss: 0.2330, Train Accuracy: 0.9226\n",
      "  Val Loss: 0.2858, Val Accuracy: 0.9041\n",
      "Epoch [6/10]\n",
      "  Train Loss: 0.2257, Train Accuracy: 0.9239\n",
      "  Val Loss: 0.2877, Val Accuracy: 0.9033\n",
      "Epoch [7/10]\n",
      "  Train Loss: 0.2202, Train Accuracy: 0.9255\n",
      "  Val Loss: 0.2895, Val Accuracy: 0.9022\n",
      "Epoch [8/10]\n",
      "  Train Loss: 0.2159, Train Accuracy: 0.9268\n",
      "  Val Loss: 0.2929, Val Accuracy: 0.9005\n",
      "Epoch [9/10]\n",
      "  Train Loss: 0.2124, Train Accuracy: 0.9276\n",
      "  Val Loss: 0.2952, Val Accuracy: 0.9000\n",
      "Epoch [10/10]\n",
      "  Train Loss: 0.2096, Train Accuracy: 0.9286\n",
      "  Val Loss: 0.2977, Val Accuracy: 0.9000\n",
      "\n",
      "Final Evaluation on Test Set:\n",
      "Test Accuracy: 0.8964\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       world       0.86      0.86      0.86      1900\n",
      "       sport       0.87      0.87      0.87      1900\n",
      "    business       0.95      0.97      0.96      1900\n",
      "    sci/tech       0.90      0.89      0.90      1900\n",
      "\n",
      "    accuracy                           0.90      7600\n",
      "   macro avg       0.90      0.90      0.90      7600\n",
      "weighted avg       0.90      0.90      0.90      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "num_classes = len(label_encoder)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Modify the train function to return both loss and accuracy\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(train_loader), accuracy\n",
    "\n",
    "# Modify the evaluate function to return probabilities\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return total_loss / len(data_loader), accuracy, all_predictions, all_labels, all_probs\n",
    "\n",
    "# Modify the train_and_validate function to return training history\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n",
    "    history = defaultdict(list)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Modify the k_fold_cross_validation function to return fold results\n",
    "def k_fold_cross_validation(X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        print(f\"\\nFold {fold}\")\n",
    "\n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = TextDataset(torch.FloatTensor(X_train_fold), torch.LongTensor(y_train_fold))\n",
    "        val_dataset = TextDataset(torch.FloatTensor(X_val_fold), torch.LongTensor(y_val_fold))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize model, criterion, and optimizer\n",
    "        model = SimpleClassifier(input_size, num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Train and validate\n",
    "        history = train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_predictions, val_labels, val_probs = evaluate(model, val_loader, criterion, device)\n",
    "        fold_results.append({\n",
    "            'history': history,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'val_predictions': val_predictions,\n",
    "            'val_labels': val_labels,\n",
    "            'val_probs': val_probs\n",
    "        })\n",
    "\n",
    "    print(\"\\nK-fold Cross-validation Results:\")\n",
    "    mean_accuracy = np.mean([result['val_accuracy'] for result in fold_results])\n",
    "    std_accuracy = np.std([result['val_accuracy'] for result in fold_results])\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"Standard Deviation: {std_accuracy:.4f}\")\n",
    "\n",
    "    return fold_results\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "fold_results = k_fold_cross_validation(X_train, y_train, k=2)\n",
    "\n",
    "# Train on full training set and evaluate on test set\n",
    "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TextDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = SimpleClassifier(input_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"\\nTraining on full training set:\")\n",
    "final_history = train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# Final evaluation on test set\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "test_loss, final_accuracy, all_predictions, all_labels, all_probs = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "target_names = [\"world\", \"sport\", \"business\", \"sci/tech\"]\n",
    "print(classification_report(all_labels, all_predictions, target_names=target_names))\n",
    "\n",
    "# Store final results\n",
    "final_results = {\n",
    "    'fold_results': fold_results,\n",
    "    'final_history': final_history,\n",
    "    'test_accuracy': final_accuracy,\n",
    "    'test_predictions': all_predictions,\n",
    "    'test_labels': all_labels,\n",
    "    'test_probs': all_probs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved as SimpleClassifier_report.md\n",
      "Report saved as SimpleClassifier_report.md\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import os\n",
    "\n",
    "def generate_report(model_name, final_results, target_names):\n",
    "    os.makedirs(\"images\", exist_ok=True)\n",
    "    report = f\"# Classification Report for {model_name}\\n\\n\"\n",
    "\n",
    "    # Model Architecture\n",
    "    report += \"## Model Architecture\\n\"\n",
    "    report += f\"```\\n{model}\\n```\\n\\n\"\n",
    "\n",
    "    # K-fold Cross-validation Results\n",
    "    report += \"## K-fold Cross-validation Results\\n\"\n",
    "    fold_accuracies = [result['val_accuracy'] for result in final_results['fold_results']]\n",
    "    report += f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}\\n\"\n",
    "    report += f\"Standard Deviation: {np.std(fold_accuracies):.4f}\\n\\n\"\n",
    "\n",
    "    # Plot K-fold Cross-validation Results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(1, len(fold_accuracies) + 1), fold_accuracies)\n",
    "    plt.title('K-fold Cross-validation Accuracies')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(f\"images/{model_name}_kfold_accuracies.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![K-fold Cross-validation Accuracies](images/{model_name}_kfold_accuracies.png)\\n\\n\"\n",
    "\n",
    "    # Training History\n",
    "    report += \"## Training History\\n\"\n",
    "    history = final_results['final_history']\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/{model_name}_training_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![Training History](images/{model_name}_training_history.png)\\n\\n\"\n",
    "\n",
    "    # Test Set Results\n",
    "    report += \"## Test Set Results\\n\"\n",
    "    report += f\"Test Accuracy: {final_results['test_accuracy']:.4f}\\n\\n\"\n",
    "\n",
    "    # Classification Report\n",
    "    report += \"## Classification Report\\n\"\n",
    "    report += \"```\\n\"\n",
    "    report += classification_report(final_results['test_labels'], final_results['test_predictions'], target_names=target_names)\n",
    "    report += \"```\\n\\n\"\n",
    "\n",
    "    # Confusion Matrix\n",
    "    report += \"## Confusion Matrix\\n\"\n",
    "    cm = confusion_matrix(final_results['test_labels'], final_results['test_predictions'])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(f\"images/{model_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![Confusion Matrix](images/{model_name}_confusion_matrix.png)\\n\\n\"\n",
    "\n",
    "    # ROC Curve\n",
    "    report += \"## ROC Curve\\n\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Convert test_probs to numpy array\n",
    "    test_probs = np.array(final_results['test_probs'])\n",
    "    \n",
    "    for i, class_name in enumerate(target_names):\n",
    "        fpr, tpr, _ = roc_curve(final_results['test_labels'], test_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f\"images/{model_name}_roc_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![ROC Curve](images/{model_name}_roc_curve.png)\\n\\n\"\n",
    "\n",
    "    # Model Summary\n",
    "    report += \"## Model Summary\\n\"\n",
    "    report += f\"- Number of epochs: {num_epochs}\\n\"\n",
    "    report += f\"- Batch size: {batch_size}\\n\"\n",
    "    report += f\"- Learning rate: {learning_rate}\\n\"\n",
    "    report += f\"- Input size: {input_size}\\n\"\n",
    "    report += f\"- Number of classes: {num_classes}\\n\"\n",
    "\n",
    "    # Save report\n",
    "    with open(f\"{model_name}_report.md\", \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    print(f\"Report saved as {model_name}_report.md\")\n",
    "\n",
    "# Generate the report\n",
    "model_name = \"SimpleClassifier\"\n",
    "target_names = [\"world\", \"sport\", \"business\", \"sci/tech\"]\n",
    "generate_report(model_name, final_results, target_names)\n",
    "\n",
    "# Generate the report\n",
    "# model_name = \"EnhancedClassifier\"\n",
    "generate_report(model_name, final_results, target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
