{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5000\n",
      "Number of classes: 4\n",
      "Train set size: 96000\n",
      "Validation set size: 24000\n",
      "Test set size: 7600\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load the data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '<NUM>', text)\n",
    "    text = re.sub(r'\\$\\d+(\\.\\d{2})?', '<MONEY>', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Preprocess the text data, concat Description and Title\n",
    "df_train['processed_text'] = (df_train[\"Title\"] + \" \" + df_train[\"Description\"]).apply(preprocess_text)\n",
    "df_test['processed_text'] = (df_test[\"Title\"] + \" \" + df_test[\"Description\"]).apply(preprocess_text)\n",
    "\n",
    "# Create CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train_full = vectorizer.fit_transform(df_train['processed_text']).toarray()\n",
    "X_test = vectorizer.transform(df_test['processed_text']).toarray()\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = {label: i for i, label in enumerate(df_train['Class Index'].unique())}\n",
    "y_train_full = df_train['Class Index'].map(label_encoder).values\n",
    "y_test = df_test['Class Index'].map(label_encoder).values\n",
    "\n",
    "# Split train data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.LongTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TextDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vectorizer.get_feature_names_out())}\")\n",
    "print(f\"Number of classes: {len(label_encoder)}\")\n",
    "print(f\"Train set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch [1/10]\n",
      "  Train Loss: 0.3665, Train Accuracy: 0.8858\n",
      "  Val Loss: 0.2911, Val Accuracy: 0.9022\n",
      "Epoch [2/10]\n",
      "  Train Loss: 0.2189, Train Accuracy: 0.9254\n",
      "  Val Loss: 0.2964, Val Accuracy: 0.8998\n",
      "Epoch [3/10]\n",
      "  Train Loss: 0.1637, Train Accuracy: 0.9427\n",
      "  Val Loss: 0.3250, Val Accuracy: 0.8983\n",
      "Epoch [4/10]\n",
      "  Train Loss: 0.1191, Train Accuracy: 0.9580\n",
      "  Val Loss: 0.3586, Val Accuracy: 0.8949\n",
      "Epoch [5/10]\n",
      "  Train Loss: 0.0817, Train Accuracy: 0.9725\n",
      "  Val Loss: 0.4122, Val Accuracy: 0.8947\n",
      "Epoch [6/10]\n",
      "  Train Loss: 0.0527, Train Accuracy: 0.9831\n",
      "  Val Loss: 0.4731, Val Accuracy: 0.8920\n",
      "Epoch [7/10]\n",
      "  Train Loss: 0.0347, Train Accuracy: 0.9898\n",
      "  Val Loss: 0.5343, Val Accuracy: 0.8910\n",
      "Epoch [8/10]\n",
      "  Train Loss: 0.0229, Train Accuracy: 0.9935\n",
      "  Val Loss: 0.6033, Val Accuracy: 0.8909\n",
      "Epoch [9/10]\n",
      "  Train Loss: 0.0163, Train Accuracy: 0.9956\n",
      "  Val Loss: 0.6654, Val Accuracy: 0.8881\n",
      "Epoch [10/10]\n",
      "  Train Loss: 0.0135, Train Accuracy: 0.9966\n",
      "  Val Loss: 0.7118, Val Accuracy: 0.8883\n",
      "\n",
      "Fold 2\n",
      "Epoch [1/10]\n",
      "  Train Loss: 0.3689, Train Accuracy: 0.8834\n",
      "  Val Loss: 0.2949, Val Accuracy: 0.8994\n",
      "Epoch [2/10]\n",
      "  Train Loss: 0.2187, Train Accuracy: 0.9258\n",
      "  Val Loss: 0.2921, Val Accuracy: 0.9008\n",
      "Epoch [3/10]\n",
      "  Train Loss: 0.1650, Train Accuracy: 0.9423\n",
      "  Val Loss: 0.3158, Val Accuracy: 0.8967\n",
      "Epoch [4/10]\n",
      "  Train Loss: 0.1190, Train Accuracy: 0.9590\n",
      "  Val Loss: 0.3533, Val Accuracy: 0.8966\n",
      "Epoch [5/10]\n",
      "  Train Loss: 0.0812, Train Accuracy: 0.9733\n",
      "  Val Loss: 0.4152, Val Accuracy: 0.8947\n",
      "Epoch [6/10]\n",
      "  Train Loss: 0.0523, Train Accuracy: 0.9831\n",
      "  Val Loss: 0.4648, Val Accuracy: 0.8910\n",
      "Epoch [7/10]\n",
      "  Train Loss: 0.0320, Train Accuracy: 0.9904\n",
      "  Val Loss: 0.5415, Val Accuracy: 0.8910\n",
      "Epoch [8/10]\n",
      "  Train Loss: 0.0214, Train Accuracy: 0.9946\n",
      "  Val Loss: 0.6079, Val Accuracy: 0.8885\n",
      "Epoch [9/10]\n",
      "  Train Loss: 0.0148, Train Accuracy: 0.9968\n",
      "  Val Loss: 0.6857, Val Accuracy: 0.8914\n",
      "Epoch [10/10]\n",
      "  Train Loss: 0.0126, Train Accuracy: 0.9972\n",
      "  Val Loss: 0.7230, Val Accuracy: 0.8897\n",
      "\n",
      "K-fold Cross-validation Results:\n",
      "Mean Accuracy: 0.8890\n",
      "Standard Deviation: 0.0007\n",
      "\n",
      "Training on full training set:\n",
      "Epoch [1/10]\n",
      "  Train Loss: 0.3226, Train Accuracy: 0.8943\n",
      "  Val Loss: 0.2739, Val Accuracy: 0.9075\n",
      "Epoch [2/10]\n",
      "  Train Loss: 0.2161, Train Accuracy: 0.9242\n",
      "  Val Loss: 0.2749, Val Accuracy: 0.9103\n",
      "Epoch [3/10]\n",
      "  Train Loss: 0.1688, Train Accuracy: 0.9400\n",
      "  Val Loss: 0.2883, Val Accuracy: 0.9084\n",
      "Epoch [4/10]\n",
      "  Train Loss: 0.1257, Train Accuracy: 0.9568\n",
      "  Val Loss: 0.3160, Val Accuracy: 0.9087\n",
      "Epoch [5/10]\n",
      "  Train Loss: 0.0885, Train Accuracy: 0.9704\n",
      "  Val Loss: 0.3593, Val Accuracy: 0.9070\n",
      "Epoch [6/10]\n",
      "  Train Loss: 0.0600, Train Accuracy: 0.9806\n",
      "  Val Loss: 0.4165, Val Accuracy: 0.9065\n",
      "Epoch [7/10]\n",
      "  Train Loss: 0.0398, Train Accuracy: 0.9874\n",
      "  Val Loss: 0.4799, Val Accuracy: 0.9022\n",
      "Epoch [8/10]\n",
      "  Train Loss: 0.0280, Train Accuracy: 0.9911\n",
      "  Val Loss: 0.5393, Val Accuracy: 0.9025\n",
      "Epoch [9/10]\n",
      "  Train Loss: 0.0209, Train Accuracy: 0.9939\n",
      "  Val Loss: 0.5885, Val Accuracy: 0.9007\n",
      "Epoch [10/10]\n",
      "  Train Loss: 0.0177, Train Accuracy: 0.9948\n",
      "  Val Loss: 0.6357, Val Accuracy: 0.8978\n",
      "\n",
      "Final Evaluation on Test Set:\n",
      "Test Accuracy: 0.8975\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       world       0.83      0.89      0.86      1900\n",
      "       sport       0.89      0.85      0.87      1900\n",
      "    business       0.96      0.96      0.96      1900\n",
      "    sci/tech       0.91      0.90      0.90      1900\n",
      "\n",
      "    accuracy                           0.90      7600\n",
      "   macro avg       0.90      0.90      0.90      7600\n",
      "weighted avg       0.90      0.90      0.90      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "hidden_size = 64\n",
    "num_classes = len(label_encoder)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Modify the train function to return both loss and accuracy\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(train_loader), accuracy\n",
    "\n",
    "# Modify the evaluate function to return probabilities\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return total_loss / len(data_loader), accuracy, all_predictions, all_labels, all_probs\n",
    "\n",
    "# Modify the train_and_validate function to return training history\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n",
    "    history = defaultdict(list)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Modify the k_fold_cross_validation function to return fold results\n",
    "def k_fold_cross_validation(X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        print(f\"\\nFold {fold}\")\n",
    "\n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = TextDataset(torch.FloatTensor(X_train_fold), torch.LongTensor(y_train_fold))\n",
    "        val_dataset = TextDataset(torch.FloatTensor(X_val_fold), torch.LongTensor(y_val_fold))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize model, criterion, and optimizer\n",
    "        model = SimpleClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Train and validate\n",
    "        history = train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_predictions, val_labels, val_probs = evaluate(model, val_loader, criterion, device)\n",
    "        fold_results.append({\n",
    "            'history': history,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'val_predictions': val_predictions,\n",
    "            'val_labels': val_labels,\n",
    "            'val_probs': val_probs\n",
    "        })\n",
    "\n",
    "    print(\"\\nK-fold Cross-validation Results:\")\n",
    "    mean_accuracy = np.mean([result['val_accuracy'] for result in fold_results])\n",
    "    std_accuracy = np.std([result['val_accuracy'] for result in fold_results])\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"Standard Deviation: {std_accuracy:.4f}\")\n",
    "\n",
    "    return fold_results\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "fold_results = k_fold_cross_validation(X_train, y_train, k=2)\n",
    "\n",
    "# Train on full training set and evaluate on test set\n",
    "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TextDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = SimpleClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"\\nTraining on full training set:\")\n",
    "final_history = train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# Final evaluation on test set\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "test_loss, final_accuracy, all_predictions, all_labels, all_probs = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "target_names = [\"world\", \"sport\", \"business\", \"sci/tech\"]\n",
    "print(classification_report(all_labels, all_predictions, target_names=target_names))\n",
    "\n",
    "# Store final results\n",
    "final_results = {\n",
    "    'fold_results': fold_results,\n",
    "    'final_history': final_history,\n",
    "    'test_accuracy': final_accuracy,\n",
    "    'test_predictions': all_predictions,\n",
    "    'test_labels': all_labels,\n",
    "    'test_probs': all_probs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved as SimpleClassifier_report.md\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import os\n",
    "\n",
    "def generate_report(model_name, final_results, target_names):\n",
    "    os.makedirs(\"images\", exist_ok=True)\n",
    "    report = f\"# Classification Report for {model_name}\\n\\n\"\n",
    "\n",
    "    # Model Architecture\n",
    "    report += \"## Model Architecture\\n\"\n",
    "    report += f\"```\\n{model}\\n```\\n\\n\"\n",
    "\n",
    "    # K-fold Cross-validation Results\n",
    "    report += \"## K-fold Cross-validation Results\\n\"\n",
    "    fold_accuracies = [result['val_accuracy'] for result in final_results['fold_results']]\n",
    "    report += f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}\\n\"\n",
    "    report += f\"Standard Deviation: {np.std(fold_accuracies):.4f}\\n\\n\"\n",
    "\n",
    "    # Plot K-fold Cross-validation Results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(1, len(fold_accuracies) + 1), fold_accuracies)\n",
    "    plt.title('K-fold Cross-validation Accuracies')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(f\"images/{model_name}_kfold_accuracies.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![K-fold Cross-validation Accuracies](images/{model_name}_kfold_accuracies.png)\\n\\n\"\n",
    "\n",
    "    # Training History\n",
    "    report += \"## Training History\\n\"\n",
    "    history = final_results['final_history']\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/{model_name}_training_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![Training History](images/{model_name}_training_history.png)\\n\\n\"\n",
    "\n",
    "    # Test Set Results\n",
    "    report += \"## Test Set Results\\n\"\n",
    "    report += f\"Test Accuracy: {final_results['test_accuracy']:.4f}\\n\\n\"\n",
    "\n",
    "    # Classification Report\n",
    "    report += \"## Classification Report\\n\"\n",
    "    report += \"```\\n\"\n",
    "    report += classification_report(final_results['test_labels'], final_results['test_predictions'], target_names=target_names)\n",
    "    report += \"```\\n\\n\"\n",
    "\n",
    "    # Confusion Matrix\n",
    "    report += \"## Confusion Matrix\\n\"\n",
    "    cm = confusion_matrix(final_results['test_labels'], final_results['test_predictions'])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(f\"images/{model_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![Confusion Matrix](images/{model_name}_confusion_matrix.png)\\n\\n\"\n",
    "\n",
    "    # ROC Curve\n",
    "    report += \"## ROC Curve\\n\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Convert test_probs to numpy array\n",
    "    test_probs = np.array(final_results['test_probs'])\n",
    "    \n",
    "    for i, class_name in enumerate(target_names):\n",
    "        fpr, tpr, _ = roc_curve(final_results['test_labels'], test_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f\"images/{model_name}_roc_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![ROC Curve](images/{model_name}_roc_curve.png)\\n\\n\"\n",
    "\n",
    "    # Model Summary\n",
    "    report += \"## Model Summary\\n\"\n",
    "    report += f\"- Number of epochs: {num_epochs}\\n\"\n",
    "    report += f\"- Batch size: {batch_size}\\n\"\n",
    "    report += f\"- Learning rate: {learning_rate}\\n\"\n",
    "    report += f\"- Hidden size: {hidden_size}\\n\"\n",
    "    report += f\"- Input size: {input_size}\\n\"\n",
    "    report += f\"- Number of classes: {num_classes}\\n\"\n",
    "\n",
    "    # Save report\n",
    "    with open(f\"{model_name}_report.md\", \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    print(f\"Report saved as {model_name}_report.md\")\n",
    "\n",
    "# Generate the report\n",
    "model_name = \"SimpleClassifier\"\n",
    "target_names = [\"world\", \"sport\", \"business\", \"sci/tech\"]\n",
    "#generate_report(model_name, final_results, target_names)\n",
    "\n",
    "# Generate the report\n",
    "model_name = \"EnhancedClassifier\"\n",
    "generate_report(model_name, final_results, target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
