{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '<NUM>', text)\n",
    "    text = re.sub(r'\\$\\d+(\\.\\d{2})?', '<MONEY>', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess the text data, concat Description and Title\n",
    "df_train['processed_text'] = (df_train[\"Title\"] + \" \" + df_train[\"Description\"]).apply(preprocess_text)\n",
    "df_test['processed_text'] = (df_test[\"Title\"] + \" \" + df_test[\"Description\"]).apply(preprocess_text)\n",
    "\n",
    "# Create TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_full = vectorizer.fit_transform(df_train['processed_text']).toarray()\n",
    "X_test = vectorizer.transform(df_test['processed_text']).toarray()\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = {label: i for i, label in enumerate(df_train['Class Index'].unique())}\n",
    "y_train_full = df_train['Class Index'].map(label_encoder).values\n",
    "y_test = df_test['Class Index'].map(label_encoder).values\n",
    "\n",
    "# Split train data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.LongTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TextDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "print(f\"Vocabulary size: {X_train.shape[1]}\")\n",
    "print(f\"Number of classes: {len(label_encoder)}\")\n",
    "print(f\"Train set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Define the improved neural network\n",
    "class ImprovedClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes, dropout_rate):\n",
    "        super(ImprovedClassifier, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.BatchNorm1d(hidden_sizes[0]))\n",
    "        self.layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.BatchNorm1d(hidden_sizes[i]))\n",
    "            self.layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(hidden_sizes[-1], num_classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "hidden_sizes = [64, 32, 16]\n",
    "num_classes = len(label_encoder)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "dropout_rate = 0.5\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# Modify the train function to include L2 regularization\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Add L2 regularization\n",
    "        l2_reg = torch.tensor(0.).to(device)\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss += weight_decay * l2_reg\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(train_loader), accuracy\n",
    "\n",
    "# Functions for evaluation and k-fold cross-validation remain the same\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return total_loss / len(data_loader), accuracy, all_predictions, all_labels, all_probs\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs):\n",
    "    history = defaultdict(list)\n",
    "    best_val_accuracy = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    return history\n",
    "\n",
    "def k_fold_cross_validation(X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        print(f\"\\nFold {fold}\")\n",
    "\n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = TextDataset(torch.FloatTensor(X_train_fold), torch.LongTensor(y_train_fold))\n",
    "        val_dataset = TextDataset(torch.FloatTensor(X_val_fold), torch.LongTensor(y_val_fold))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize model, criterion, and optimizer\n",
    "        model = ImprovedClassifier(input_size, hidden_sizes, num_classes, dropout_rate).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "        # Train and validate\n",
    "        history = train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_predictions, val_labels, val_probs = evaluate(model, val_loader, criterion, device)\n",
    "        fold_results.append({\n",
    "            'history': history,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'val_predictions': val_predictions,\n",
    "            'val_labels': val_labels,\n",
    "            'val_probs': val_probs\n",
    "        })\n",
    "\n",
    "    print(\"\\nK-fold Cross-validation Results:\")\n",
    "    mean_accuracy = np.mean([result['val_accuracy'] for result in fold_results])\n",
    "    std_accuracy = np.std([result['val_accuracy'] for result in fold_results])\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"Standard Deviation: {std_accuracy:.4f}\")\n",
    "\n",
    "    return fold_results\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "fold_results = k_fold_cross_validation(X_train, y_train, k=2)\n",
    "\n",
    "# Train on full training set and evaluate on test set\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "model = ImprovedClassifier(input_size, hidden_sizes, num_classes, dropout_rate).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "print(\"\\nTraining on full training set:\")\n",
    "final_history = train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs)\n",
    "\n",
    "# Final evaluation on test set\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "test_loss, final_accuracy, all_predictions, all_labels, all_probs = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "target_names = [\"world\", \"sport\", \"business\", \"sci/tech\"]\n",
    "print(classification_report(all_labels, all_predictions, target_names=target_names))\n",
    "\n",
    "# Store final results\n",
    "final_results = {\n",
    "    'fold_results': fold_results,\n",
    "    'final_history': final_history,\n",
    "    'test_accuracy': final_accuracy,\n",
    "    'test_predictions': all_predictions,\n",
    "    'test_labels': all_labels,\n",
    "    'test_probs': all_probs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import os\n",
    "\n",
    "def generate_report(model_name, final_results, target_names):\n",
    "    os.makedirs(\"images\", exist_ok=True)\n",
    "    report = f\"# Classification Report for {model_name}\\n\\n\"\n",
    "\n",
    "    # Model Architecture\n",
    "    report += \"## Model Architecture\\n\"\n",
    "    report += f\"```\\n{model}\\n```\\n\\n\"\n",
    "\n",
    "    # K-fold Cross-validation Results\n",
    "    report += \"## K-fold Cross-validation Results\\n\"\n",
    "    fold_accuracies = [result['val_accuracy'] for result in final_results['fold_results']]\n",
    "    report += f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}\\n\"\n",
    "    report += f\"Standard Deviation: {np.std(fold_accuracies):.4f}\\n\\n\"\n",
    "\n",
    "    # Plot K-fold Cross-validation Results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(1, len(fold_accuracies) + 1), fold_accuracies)\n",
    "    plt.title('K-fold Cross-validation Accuracies')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(f\"images/{model_name}_kfold_accuracies.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![K-fold Cross-validation Accuracies](images/{model_name}_kfold_accuracies.png)\\n\\n\"\n",
    "\n",
    "    # Training History\n",
    "    report += \"## Training History\\n\"\n",
    "    history = final_results['final_history']\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/{model_name}_training_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![Training History](images/{model_name}_training_history.png)\\n\\n\"\n",
    "\n",
    "    # Test Set Results\n",
    "    report += \"## Test Set Results\\n\"\n",
    "    report += f\"Test Accuracy: {final_results['test_accuracy']:.4f}\\n\\n\"\n",
    "\n",
    "    # Classification Report\n",
    "    report += \"## Classification Report\\n\"\n",
    "    report += \"```\\n\"\n",
    "    report += classification_report(final_results['test_labels'], final_results['test_predictions'], target_names=target_names)\n",
    "    report += \"```\\n\\n\"\n",
    "\n",
    "    # Confusion Matrix\n",
    "    report += \"## Confusion Matrix\\n\"\n",
    "    cm = confusion_matrix(final_results['test_labels'], final_results['test_predictions'])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(f\"images/{model_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![Confusion Matrix](images/{model_name}_confusion_matrix.png)\\n\\n\"\n",
    "\n",
    "    # ROC Curve\n",
    "    report += \"## ROC Curve\\n\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Convert test_probs to numpy array\n",
    "    test_probs = np.array(final_results['test_probs'])\n",
    "    \n",
    "    for i, class_name in enumerate(target_names):\n",
    "        fpr, tpr, _ = roc_curve(final_results['test_labels'], test_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f\"images/{model_name}_roc_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "    report += f\"![ROC Curve](images/{model_name}_roc_curve.png)\\n\\n\"\n",
    "\n",
    "    # Model Summary\n",
    "    report += \"## Model Summary\\n\"\n",
    "    report += f\"- Number of epochs: {num_epochs}\\n\"\n",
    "    report += f\"- Batch size: {batch_size}\\n\"\n",
    "    report += f\"- Learning rate: {learning_rate}\\n\"\n",
    "    report += f\"- Input size: {input_size}\\n\"\n",
    "    report += f\"- Number of classes: {num_classes}\\n\"\n",
    "\n",
    "    # Save report\n",
    "    with open(f\"{model_name}_report.md\", \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    print(f\"Report saved as {model_name}_report.md\")\n",
    "    \n",
    "# Generate the report\n",
    "model_name = \"ImprovedClassifier\"\n",
    "generate_report(model_name, final_results, target_names)\n",
    "\n",
    "# Suggestion for alternative input encoding method\n",
    "print(\"\\nSuggestion for alternative input encoding method:\")\n",
    "print(\"Consider using word embeddings, such as Word2Vec or GloVe, instead of TF-IDF.\")\n",
    "print(\"Word embeddings capture semantic relationships between words and may yield better results.\")\n",
    "print(\"To implement this, you would need to:\")\n",
    "print(\"1. Use a pre-trained word embedding model or train your own on a large corpus.\")\n",
    "print(\"2. Convert each document to a sequence of word vectors.\")\n",
    "print(\"3. Use padding to ensure all sequences have the same length.\")\n",
    "print(\"4. Modify the model architecture to include an embedding layer and possibly use RNNs or CNNs.\")\n",
    "print(\"This approach could potentially capture more nuanced relationships in the text data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
